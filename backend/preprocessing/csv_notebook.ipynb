{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess food dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Varshini\\CourseWork\\Dissertation\\Implementation\\Github\\Recommendation_Dissertation\\backend\\preprocessing\\datasets\\Food_recommender\\\n"
     ]
    }
   ],
   "source": [
    "current_working_directory = os.getcwd()\n",
    "\n",
    "# Set location to Datasets\n",
    "dataset_location = current_working_directory + '\\\\datasets\\\\Food_recommender\\\\'\n",
    "\n",
    "print(dataset_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 18)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File list\n",
    "file_list = ['Appetizers.csv', 'Beverages.csv', 'Breads.csv', 'Breakfast.csv',\n",
    "             'Desserts.csv', 'Dressings.csv', 'Main.csv', 'Salads.csv', 'Sandwiches.csv', 'Snacks.csv', 'Soups.csv']\n",
    "\n",
    "combined_csv = pd.concat([pd.read_csv(dataset_location + file)\n",
    "                         for file in file_list], ignore_index=True)\n",
    "combined_csv.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1222, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 18)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicate rows\n",
    "food_data = combined_csv.drop_duplicates()\n",
    "print(food_data.shape)\n",
    "\n",
    "# Check if any more duplicate rows\n",
    "df2 = food_data[food_data.duplicated()]\n",
    "df2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>servings</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>directions</th>\n",
       "      <th>type</th>\n",
       "      <th>calories</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fat</th>\n",
       "      <th>carbohydrates</th>\n",
       "      <th>fiber</th>\n",
       "      <th>sugars</th>\n",
       "      <th>protein</th>\n",
       "      <th>calcium</th>\n",
       "      <th>iron</th>\n",
       "      <th>vitamin_a</th>\n",
       "      <th>vitamin_c</th>\n",
       "      <th>vitamin_d</th>\n",
       "      <th>folate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ambrosia</td>\n",
       "      <td>8 servings</td>\n",
       "      <td>['1 can pineapple chunks (in juice, 20 oz., dr...</td>\n",
       "      <td>['Drain pineapple and oranges. Use juice as be...</td>\n",
       "      <td>Appetizers</td>\n",
       "      <td>139</td>\n",
       "      <td>2 mg</td>\n",
       "      <td>2 g</td>\n",
       "      <td>31 g</td>\n",
       "      <td>2 g</td>\n",
       "      <td>26 g</td>\n",
       "      <td>3 g</td>\n",
       "      <td>70 mg</td>\n",
       "      <td>1 mg</td>\n",
       "      <td>27 mcg RAE</td>\n",
       "      <td>20 mg</td>\n",
       "      <td>0 mcg</td>\n",
       "      <td>13 mcg DFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baked Cauliflower Tots</td>\n",
       "      <td>3 Servings</td>\n",
       "      <td>['2 cups grated or finely chopped cauliflower ...</td>\n",
       "      <td>['Wash hands with soap and water.', 'Preheat o...</td>\n",
       "      <td>Appetizers</td>\n",
       "      <td>107</td>\n",
       "      <td>72 mg</td>\n",
       "      <td>5 g</td>\n",
       "      <td>9 g</td>\n",
       "      <td>2 g</td>\n",
       "      <td>1 g</td>\n",
       "      <td>7 g</td>\n",
       "      <td>93 mg</td>\n",
       "      <td>1 mg</td>\n",
       "      <td>52 mcg RAE</td>\n",
       "      <td>32 mg</td>\n",
       "      <td>0 mcg</td>\n",
       "      <td>70 mcg DFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baked Chicken Nuggets</td>\n",
       "      <td>4 servings</td>\n",
       "      <td>['1 1/2 pounds chicken thighs, boneless, skinl...</td>\n",
       "      <td>['Remove skin and bone; cut thighs into bite-s...</td>\n",
       "      <td>Appetizers</td>\n",
       "      <td>175</td>\n",
       "      <td>67 mg</td>\n",
       "      <td>8 g</td>\n",
       "      <td>7 g</td>\n",
       "      <td>1 g</td>\n",
       "      <td>1 g</td>\n",
       "      <td>18 g</td>\n",
       "      <td>13 mg</td>\n",
       "      <td>3 mg</td>\n",
       "      <td>54 mcg RAE</td>\n",
       "      <td>2 mg</td>\n",
       "      <td>0 mcg</td>\n",
       "      <td>45 mcg DFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baked Tortilla Chips</td>\n",
       "      <td>6 Servings</td>\n",
       "      <td>['3 whole wheat flour tortillas, 10\" across (o...</td>\n",
       "      <td>['Wash hands with soap and water.', 'Preheat o...</td>\n",
       "      <td>Appetizers</td>\n",
       "      <td>93</td>\n",
       "      <td>0 mg</td>\n",
       "      <td>1 g</td>\n",
       "      <td>20 g</td>\n",
       "      <td>2 g</td>\n",
       "      <td>0 g</td>\n",
       "      <td>3 g</td>\n",
       "      <td>8 mg</td>\n",
       "      <td>1 mg</td>\n",
       "      <td>0 mcg RAE</td>\n",
       "      <td>0 mg</td>\n",
       "      <td>0 mcg</td>\n",
       "      <td>22 mcg DFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beet &amp; White Bean Salad</td>\n",
       "      <td>4 Servings</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Prepare dressing: In small bowl combine cide...</td>\n",
       "      <td>Appetizers</td>\n",
       "      <td>420</td>\n",
       "      <td>13 mg</td>\n",
       "      <td>29 g</td>\n",
       "      <td>29 g</td>\n",
       "      <td>7 g</td>\n",
       "      <td>5 g</td>\n",
       "      <td>14 g</td>\n",
       "      <td>169 mg</td>\n",
       "      <td>3 mg</td>\n",
       "      <td>34 mcg RAE</td>\n",
       "      <td>3 mg</td>\n",
       "      <td>0 mcg</td>\n",
       "      <td>122 mcg DFE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name    servings   \n",
       "0                 Ambrosia  8 servings  \\\n",
       "1   Baked Cauliflower Tots  3 Servings   \n",
       "2    Baked Chicken Nuggets  4 servings   \n",
       "3     Baked Tortilla Chips  6 Servings   \n",
       "4  Beet & White Bean Salad  4 Servings   \n",
       "\n",
       "                                         ingredients   \n",
       "0  ['1 can pineapple chunks (in juice, 20 oz., dr...  \\\n",
       "1  ['2 cups grated or finely chopped cauliflower ...   \n",
       "2  ['1 1/2 pounds chicken thighs, boneless, skinl...   \n",
       "3  ['3 whole wheat flour tortillas, 10\" across (o...   \n",
       "4                                                 []   \n",
       "\n",
       "                                          directions        type  calories   \n",
       "0  ['Drain pineapple and oranges. Use juice as be...  Appetizers       139  \\\n",
       "1  ['Wash hands with soap and water.', 'Preheat o...  Appetizers       107   \n",
       "2  ['Remove skin and bone; cut thighs into bite-s...  Appetizers       175   \n",
       "3  ['Wash hands with soap and water.', 'Preheat o...  Appetizers        93   \n",
       "4  ['Prepare dressing: In small bowl combine cide...  Appetizers       420   \n",
       "\n",
       "  cholesterol   fat carbohydrates fiber sugars protein calcium  iron   \n",
       "0        2 mg   2 g          31 g   2 g   26 g     3 g   70 mg  1 mg  \\\n",
       "1       72 mg   5 g           9 g   2 g    1 g     7 g   93 mg  1 mg   \n",
       "2       67 mg   8 g           7 g   1 g    1 g    18 g   13 mg  3 mg   \n",
       "3        0 mg   1 g          20 g   2 g    0 g     3 g    8 mg  1 mg   \n",
       "4       13 mg  29 g          29 g   7 g    5 g    14 g  169 mg  3 mg   \n",
       "\n",
       "    vitamin_a vitamin_c vitamin_d       folate  \n",
       "0  27 mcg RAE     20 mg     0 mcg   13 mcg DFE  \n",
       "1  52 mcg RAE     32 mg     0 mcg   70 mcg DFE  \n",
       "2  54 mcg RAE      2 mg     0 mcg   45 mcg DFE  \n",
       "3   0 mcg RAE      0 mg     0 mcg   22 mcg DFE  \n",
       "4  34 mcg RAE      3 mg     0 mcg  122 mcg DFE  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write combined csv into new csv\n",
    "food_data.to_csv(dataset_location + 'food_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100004, 3)\n",
      "(72853, 3)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "csv_file = 'D:\\\\Varshini\\\\CourseWork\\\\Dissertation\\\\Implementation\\\\Github\\\\Recommendation_Dissertation\\\\backend\\\\preprocessing\\\\cleanedDatasets\\\\ratings_cleaned.csv'\n",
    "rating = pd.read_csv(csv_file)\n",
    "\n",
    "# Print rows with food_id greater than 1117 - to check if they exists\n",
    "rating = rating[rating.food_id > 1117]\n",
    "\n",
    "# Randomly choose food_id between the range of values greater than 1117\n",
    "def clean(x):\n",
    "    if x > 1117:\n",
    "        return random.randrange(1, 1118)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "rating['food_id'] = rating['food_id'].apply(lambda food_id: clean(x=food_id))\n",
    "\n",
    "rating.head()\n",
    "\n",
    "# Write the modified ratings\n",
    "rating.to_csv('D:\\\\Varshini\\\\CourseWork\\\\Dissertation\\\\Implementation\\\\Github\\\\Recommendation_Dissertation\\\\backend\\\\preprocessing\\\\cleanedDatasets\\\\' + 'ratings_cleaned.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess ADL datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>sensor_status</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-04-02 07:12:05.002864</td>\n",
       "      <td>M005</td>\n",
       "      <td>ON</td>\n",
       "      <td>Cook_begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-04-02 07:12:05.999979</td>\n",
       "      <td>M002</td>\n",
       "      <td>ON</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-04-02 07:12:08.061644</td>\n",
       "      <td>M006</td>\n",
       "      <td>ON</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-04-02 07:12:09.655459</td>\n",
       "      <td>M005</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-04-02 07:12:10.656179</td>\n",
       "      <td>M002</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     datetime sensor_id sensor_status    activity\n",
       "0  2009-04-02 07:12:05.002864      M005            ON  Cook_begin\n",
       "1  2009-04-02 07:12:05.999979      M002            ON         NaN\n",
       "2  2009-04-02 07:12:08.061644      M006            ON         NaN\n",
       "3  2009-04-02 07:12:09.655459      M005           OFF         NaN\n",
       "4  2009-04-02 07:12:10.656179      M002           OFF         NaN"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "dataset_location = 'D:\\\\Varshini\\\\CourseWork\\\\Dissertation\\\\Implementation\\\\Github\\\\Recommendation_Dissertation\\\\backend\\\\preprocessing\\\\datasets\\\\Activity_predictor\\\\request\\\\'\n",
    "\n",
    "# with open(dataset_location + 'data-1.txt', 'rt') as infile, open(dataset_location + 'data.csv', 'w') as outfile:\n",
    "#     for line in infile:\n",
    "#         if re.search(r'\\d+$', line.strip()):\n",
    "#             modified_line = line.strip() + ',\\n'\n",
    "#         else:\n",
    "#             modified_line = line\n",
    "\n",
    "#         outfile.write(modified_line.replace('\\t', ',').replace(' ', '_').replace('ON\\n', 'ON,\\n').replace('OFF\\n', 'OFF,\\n'))\n",
    "# infile.close()\n",
    "# outfile.close()\n",
    "\n",
    "# # Read CSV\n",
    "# csv_file = pd.read_csv(dataset_location + 'data.csv', header=None)\n",
    "\n",
    "# # Adding header\n",
    "# headerList = ['datetime', 'sensor_id', 'sensor_status', 'activity']\n",
    "\n",
    "# converting data frame to csv\n",
    "# csv_file.to_csv(dataset_location + 'data.csv',header=headerList, index=False)\n",
    "csv_file = pd.read_csv(dataset_location + 'data.csv')\n",
    "csv_file['datetime'] = csv_file['datetime'].str.replace('_', ' ')\n",
    "csv_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>activity</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-02-02</td>\n",
       "      <td>07:15:16.575809</td>\n",
       "      <td>R1_Bed_to_Toilet_begin</td>\n",
       "      <td>2009-02-02 07:15:16.575809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2009-02-02</td>\n",
       "      <td>07:21:03.792759</td>\n",
       "      <td>R1_Bed_to_Toilet_end</td>\n",
       "      <td>2009-02-02 07:21:03.792759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2009-02-02</td>\n",
       "      <td>07:21:04.014729</td>\n",
       "      <td>R1_Personal_Hygiene_begin</td>\n",
       "      <td>2009-02-02 07:21:04.014729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2009-02-02</td>\n",
       "      <td>07:38:33.946559</td>\n",
       "      <td>R1_Personal_Hygiene_end</td>\n",
       "      <td>2009-02-02 07:38:33.946559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2009-02-02</td>\n",
       "      <td>07:44:12.597919</td>\n",
       "      <td>R2_Bed_to_Toilet_begin</td>\n",
       "      <td>2009-02-02 07:44:12.597919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date             time                   activity   \n",
       "0    2009-02-02  07:15:16.575809     R1_Bed_to_Toilet_begin  \\\n",
       "80   2009-02-02  07:21:03.792759       R1_Bed_to_Toilet_end   \n",
       "81   2009-02-02  07:21:04.014729  R1_Personal_Hygiene_begin   \n",
       "182  2009-02-02  07:38:33.946559    R1_Personal_Hygiene_end   \n",
       "183  2009-02-02  07:44:12.597919     R2_Bed_to_Toilet_begin   \n",
       "\n",
       "                       datetime  \n",
       "0    2009-02-02 07:15:16.575809  \n",
       "80   2009-02-02 07:21:03.792759  \n",
       "81   2009-02-02 07:21:04.014729  \n",
       "182  2009-02-02 07:38:33.946559  \n",
       "183  2009-02-02 07:44:12.597919  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "subset_file = csv_file.dropna()\n",
    "subset_file.drop(['sensor_id', 'sensor_status'], axis=1, inplace=True)\n",
    "subset_file['datetime'] = (subset_file['date'] + ' ' + subset_file['time'])\n",
    "subset_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>activity</th>\n",
       "      <th>datetime</th>\n",
       "      <th>activity_name</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-02-02</td>\n",
       "      <td>07:15:16.575809</td>\n",
       "      <td>R1_Bed_to_Toilet_begin</td>\n",
       "      <td>2009-02-02 07:15:16.575809</td>\n",
       "      <td>Bed_to_Toilet</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2009-02-02</td>\n",
       "      <td>07:21:03.792759</td>\n",
       "      <td>R1_Bed_to_Toilet_end</td>\n",
       "      <td>2009-02-02 07:21:03.792759</td>\n",
       "      <td>Bed_to_Toilet</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2009-02-02</td>\n",
       "      <td>07:21:04.014729</td>\n",
       "      <td>R1_Personal_Hygiene_begin</td>\n",
       "      <td>2009-02-02 07:21:04.014729</td>\n",
       "      <td>Personal_Hygiene</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2009-02-02</td>\n",
       "      <td>07:38:33.946559</td>\n",
       "      <td>R1_Personal_Hygiene_end</td>\n",
       "      <td>2009-02-02 07:38:33.946559</td>\n",
       "      <td>Personal_Hygiene</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2009-02-02</td>\n",
       "      <td>07:44:12.597919</td>\n",
       "      <td>R2_Bed_to_Toilet_begin</td>\n",
       "      <td>2009-02-02 07:44:12.597919</td>\n",
       "      <td>Bed_to_Toilet</td>\n",
       "      <td>R2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date             time                   activity   \n",
       "0    2009-02-02  07:15:16.575809     R1_Bed_to_Toilet_begin  \\\n",
       "80   2009-02-02  07:21:03.792759       R1_Bed_to_Toilet_end   \n",
       "81   2009-02-02  07:21:04.014729  R1_Personal_Hygiene_begin   \n",
       "182  2009-02-02  07:38:33.946559    R1_Personal_Hygiene_end   \n",
       "183  2009-02-02  07:44:12.597919     R2_Bed_to_Toilet_begin   \n",
       "\n",
       "                       datetime     activity_name user_id  \n",
       "0    2009-02-02 07:15:16.575809     Bed_to_Toilet      R1  \n",
       "80   2009-02-02 07:21:03.792759     Bed_to_Toilet      R1  \n",
       "81   2009-02-02 07:21:04.014729  Personal_Hygiene      R1  \n",
       "182  2009-02-02 07:38:33.946559  Personal_Hygiene      R1  \n",
       "183  2009-02-02 07:44:12.597919     Bed_to_Toilet      R2  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_file.loc[subset_file['activity'].str.startswith('R'), 'activity_name'] = subset_file['activity'].str.split('_', n=1, expand=True)[1]\n",
    "subset_file.loc[~subset_file['activity'].str.startswith('R'), 'activity_name'] = subset_file['activity']\n",
    "\n",
    "subset_file.loc[subset_file['activity'].str.startswith('R'), 'user_id'] = subset_file['activity'].str.split('_', n=1, expand=True)[0]\n",
    "subset_file.loc[~subset_file['activity'].str.startswith('R'), 'user_id'] = 'Both'\n",
    "\n",
    "subset_file['activity_name'] = subset_file['activity_name'].replace(\"_begin\", \"\", regex=True)\n",
    "subset_file['activity_name'] = subset_file['activity_name'].replace(\"_end\", \"\", regex=True)\n",
    "\n",
    "subset_file.head()\n",
    "\n",
    "# subset_file.to_csv(dataset_location + 'ADL_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sureshv\\AppData\\Local\\Temp\\ipykernel_5436\\2897989765.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  merged_df['activity_duration'] = pd.to_datetime(merged_df['time_end']) - pd.to_datetime(merged_df['time_begin'])\n",
      "C:\\Users\\sureshv\\AppData\\Local\\Temp\\ipykernel_5436\\2897989765.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  merged_df['activity_duration'] = pd.to_datetime(merged_df['time_end']) - pd.to_datetime(merged_df['time_begin'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time_begin</th>\n",
       "      <th>activity_begin</th>\n",
       "      <th>activity_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>time_end</th>\n",
       "      <th>activity_end</th>\n",
       "      <th>activity_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-02-02</td>\n",
       "      <td>07:15:16.575809</td>\n",
       "      <td>R1_Bed_to_Toilet_begin</td>\n",
       "      <td>Bed_to_Toilet</td>\n",
       "      <td>R1</td>\n",
       "      <td>07:21:03.792759</td>\n",
       "      <td>R1_Bed_to_Toilet_end</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-02-02</td>\n",
       "      <td>07:21:04.014729</td>\n",
       "      <td>R1_Personal_Hygiene_begin</td>\n",
       "      <td>Personal_Hygiene</td>\n",
       "      <td>R1</td>\n",
       "      <td>07:38:33.946559</td>\n",
       "      <td>R1_Personal_Hygiene_end</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-02-02</td>\n",
       "      <td>07:44:12.597919</td>\n",
       "      <td>R2_Bed_to_Toilet_begin</td>\n",
       "      <td>Bed_to_Toilet</td>\n",
       "      <td>R2</td>\n",
       "      <td>07:46:55.1379</td>\n",
       "      <td>R2_Bed_to_Toilet_end</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-02-02</td>\n",
       "      <td>07:47:19.239909</td>\n",
       "      <td>Meal_Preparation_begin</td>\n",
       "      <td>Meal_Preparation</td>\n",
       "      <td>Both</td>\n",
       "      <td>07:55:23.86221</td>\n",
       "      <td>Meal_Preparation_end</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-02-02</td>\n",
       "      <td>07:47:19.239909</td>\n",
       "      <td>Meal_Preparation_begin</td>\n",
       "      <td>Meal_Preparation</td>\n",
       "      <td>Both</td>\n",
       "      <td>10:41:52.005729</td>\n",
       "      <td>Meal_Preparation_end</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       time_begin             activity_begin     activity_name   \n",
       "0  2009-02-02  07:15:16.575809     R1_Bed_to_Toilet_begin     Bed_to_Toilet  \\\n",
       "1  2009-02-02  07:21:04.014729  R1_Personal_Hygiene_begin  Personal_Hygiene   \n",
       "2  2009-02-02  07:44:12.597919     R2_Bed_to_Toilet_begin     Bed_to_Toilet   \n",
       "3  2009-02-02  07:47:19.239909     Meal_Preparation_begin  Meal_Preparation   \n",
       "4  2009-02-02  07:47:19.239909     Meal_Preparation_begin  Meal_Preparation   \n",
       "\n",
       "  user_id         time_end             activity_end  activity_duration  \n",
       "0      R1  07:21:03.792759     R1_Bed_to_Toilet_end                6.0  \n",
       "1      R1  07:38:33.946559  R1_Personal_Hygiene_end               17.0  \n",
       "2      R2    07:46:55.1379     R2_Bed_to_Toilet_end                3.0  \n",
       "3    Both   07:55:23.86221     Meal_Preparation_end                8.0  \n",
       "4    Both  10:41:52.005729     Meal_Preparation_end              175.0  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not needed\n",
    "\n",
    "activity_begin_rows = subset_file[subset_file['activity'].str.endswith('_begin')]\n",
    "activity_end_rows = subset_file[subset_file['activity'].str.endswith('_end')]\n",
    "\n",
    "merged_df = pd.merge(activity_begin_rows, activity_end_rows, how='outer', on=['activity_name', 'user_id', 'date'], suffixes=('_begin', '_end'))\n",
    "merged_df['activity_duration'] = pd.to_datetime(merged_df['time_end']) - pd.to_datetime(merged_df['time_begin'])\n",
    "merged_df['activity_duration'] = round(merged_df['activity_duration'].dt.total_seconds()/60)\n",
    "\n",
    "merged_df.to_csv(dataset_location + 'ADL_merged.csv', index=False)\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bed_to_Toilet', 'Personal_Hygiene', 'Meal_Preparation',\n",
       "       'Watch_TV', 'Work', 'Sleep', 'Wash_Bathtub', 'Clean', 'Study',\n",
       "       'sleep', 'wakeup', 'Grooming', 'shower', 'work', 'Cooking',\n",
       "       'Cleaning', 'Bed_toilet_transition'], dtype=object)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_file = pd.read_csv(\"D:\\Varshini\\CourseWork\\Dissertation\\Implementation\\Local\\Datasets\\9_Tulum_Daily_life_2009\")\n",
    "\n",
    "subset_file['activity_name'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R1': {'Bed_to_Toilet': 337.0597941, 'Personal_Hygiene': 663.3175621333334, 'Work': 6179.465778383333, 'Sleep': 18428.362785666668}, 'R2': {'Bed_to_Toilet': 94.54992920000001, 'Personal_Hygiene': 1029.4742460999998, 'Work': 2530.0274137166675, 'Sleep': 18572.112062366665}, 'Both': {'Meal_Preparation': 6245.816080033337, 'Watch_TV': 3228.7769552999994, 'Wash_Bathtub': 33.09008768333334, 'Clean': 49.75285231666666, 'Study': 922.7055899000001}}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "ongoing_activities = {}\n",
    "activity_tracking = {}\n",
    "user_ids = subset_file['user_id'].drop_duplicates().values\n",
    "for id in user_ids:\n",
    "    ongoing_activities[id] = {}\n",
    "    activity_tracking[id] = {}\n",
    "\n",
    "for index, row in subset_file.iterrows():\n",
    "    activity =  row['activity']\n",
    "    activity_name = row['activity_name']\n",
    "    user_id = row['user_id']\n",
    "    time = datetime.strptime(row['datetime'], \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    time_1 = timedelta(hours=time.hour, minutes=time.minute, seconds=time.second)\n",
    "\n",
    "    if activity.endswith('begin'):\n",
    "        ongoing_activities[user_id][activity_name] = time\n",
    "        if activity_name not in activity_tracking[user_id]:\n",
    "            activity_tracking[user_id][activity_name] = 0 #mins\n",
    "\n",
    "    elif activity.endswith('end'):\n",
    "        activity_tag = activity.split('_', maxsplit=1)[1]\n",
    "        begin_timestamp = ongoing_activities[user_id][activity_name]\n",
    "        if begin_timestamp:\n",
    "            time_spent = time - begin_timestamp\n",
    "            activity_tracking[user_id][activity_name] += time_spent.total_seconds()/60\n",
    "\n",
    "print(activity_tracking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R1': {'Bed_to_Toilet': 6, 'Personal_Hygiene': 11, 'Work': 101, 'Sleep': 302, 'Meal_Preparation': 102, 'Watch_TV': 53, 'Wash_Bathtub': 1, 'Clean': 1, 'Study': 15}, 'R2': {'Bed_to_Toilet': 2, 'Personal_Hygiene': 17, 'Work': 41, 'Sleep': 304, 'Meal_Preparation': 102, 'Watch_TV': 53, 'Wash_Bathtub': 1, 'Clean': 1, 'Study': 15}}\n"
     ]
    }
   ],
   "source": [
    "# Normalise and combine activities by both\n",
    "start = datetime.strptime(subset_file.iloc[0]['datetime'], \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "end =  datetime.strptime(subset_file.iloc[-1]['datetime'], \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "\n",
    "total_days = (end - start).days\n",
    "\n",
    "combined_activities  = activity_tracking['Both']\n",
    "\n",
    "for user_id, activities in activity_tracking.items():\n",
    "    activity_tracking[user_id].update(combined_activities)\n",
    "    for activity, duration in activities.items():\n",
    "        activity_tracking[user_id][activity] = round(duration/total_days)\n",
    "\n",
    "activity_tracking.pop('Both')\n",
    "print(activity_tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R1': {'Sleep': 302, 'Meal_Preparation': 102, 'Work': 101, 'Watch_TV': 53, 'Study': 15, 'Personal_Hygiene': 11, 'Bed_to_Toilet': 6, 'Wash_Bathtub': 1, 'Clean': 1}, 'R2': {'Sleep': 304, 'Meal_Preparation': 102, 'Watch_TV': 53, 'Work': 41, 'Personal_Hygiene': 17, 'Study': 15, 'Bed_to_Toilet': 2, 'Wash_Bathtub': 1, 'Clean': 1}}\n"
     ]
    }
   ],
   "source": [
    "# Sort activities by reverse\n",
    "\n",
    "sorted_activities = {key : dict(sorted(value.items(), reverse=True, key = lambda element: element[1]))\n",
    "                     for key, value in activity_tracking.items()}\n",
    "\n",
    "print(sorted_activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R1': {'Sleep': 302, 'Meal_Preparation': 102, 'Work': 101, 'Watch_TV': 53, 'Study': 15, 'Personal_Hygiene': 11, 'Bed_to_Toilet': 6, 'Wash_Bathtub': 1, 'Clean': 1}, 'R2': {'Sleep': 304, 'Meal_Preparation': 102, 'Watch_TV': 53, 'Work': 41, 'Personal_Hygiene': 17, 'Study': 15, 'Bed_to_Toilet': 2, 'Wash_Bathtub': 1, 'Clean': 1}}\n",
      "1\n",
      "R1 active\n",
      "2\n",
      "R2 active\n"
     ]
    }
   ],
   "source": [
    "# Determine their level of activity\n",
    "\n",
    "sorted_activities={'R1': {'Sleep': 302, 'Meal_Preparation': 102, 'Work': 101, 'Watch_TV': 53, 'Study': 15, 'Personal_Hygiene': 11, 'Bed_to_Toilet': 6, 'Wash_Bathtub': 1, 'Clean': 1}, 'R2': {'Sleep': 304, 'Meal_Preparation': 102, 'Watch_TV': 53, 'Work': 41, 'Personal_Hygiene': 17, 'Study': 15, 'Bed_to_Toilet': 2, 'Wash_Bathtub': 1, 'Clean': 1}}\n",
    "\n",
    "print(sorted_activities)\n",
    "\n",
    "ACTIVITY_LEVELS = {\n",
    "    'sedentary': ['Watch_TV', 'Study'],\n",
    "    'low_active': ['Personal_Hygiene', 'Bed_to_Toilet'],\n",
    "    'active': ['Work', 'Wash_Bathtub', 'Clean', 'Meal_Preparation'],\n",
    "    'very_active': ['Exercise', 'Run', 'Jog']\n",
    "}\n",
    "user_level_activity = {}\n",
    "\n",
    "level_of_activity = {\n",
    "    'sedentary': 0,\n",
    "    'low_active': 0,\n",
    "    'active': 0,\n",
    "    'very_active': 0\n",
    "}\n",
    "\n",
    "for user_id, user_activities in sorted_activities.items():\n",
    "    level_of_activity = {\n",
    "    'sedentary': 0,\n",
    "    'low_active': 0,\n",
    "    'active': 0,\n",
    "    'very_active': 0\n",
    "    }\n",
    "    for user_activity, duration in user_activities.items():\n",
    "        for level, activity in ACTIVITY_LEVELS.items():\n",
    "            if (user_activity in activity):\n",
    "                level_of_activity[level] += duration\n",
    "\n",
    "    user_level_activity[user_id] = level_of_activity\n",
    "\n",
    "# Find greatest level of activity\n",
    "for user_id, user_level in user_level_activity.items():\n",
    "    print(user_id[1:])\n",
    "    print(user_id + \" \" + max(user_level, key=user_level.get))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommend Meal times for a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Morning': 7, 'Morning activities 1': 8, 'Morning snack': 10, 'Morning activities 2': 13, 'Lunch': 14, 'Afternoon activities': 17, 'Afternoon Snack': 18, 'Evening activities': 20, 'Dinner': 21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Varshini\\CourseWork\\venv\\venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot  as plt\n",
    "from statistics import mean\n",
    "\n",
    "subset_file = pd.read_csv(\"D:\\\\Varshini\\\\CourseWork\\\\Dissertation\\\\Implementation\\\\Github\\\\Recommendation_Dissertation\\\\backend\\\\preprocessing\\\\cleanedDatasets\\\\ADL\\\\data-cleaned.csv\")\n",
    "\n",
    "subset_file.head()\n",
    "\n",
    "# Convert 'date' and 'time' into datetime format and set it as index\n",
    "# data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'])\n",
    "\n",
    "subset_file['datetime'] = pd.to_datetime(subset_file['datetime'])\n",
    "subset_file['hour'] = subset_file['datetime'].dt.hour\n",
    "subset_file['minute'] = subset_file['datetime'].dt.minute\n",
    "# subset_file.set_index('datetime', inplace=True)\n",
    "\n",
    "# Considering less active or sedentary activities as 'idle' times, replace with your conditions\n",
    "idle_activities = ['Study', 'Watch_TV', 'Personal_Hygiene', 'Bed_to_Toilet'] \n",
    "subset_file['idle'] = subset_file['activity_name'].isin(idle_activities).astype(int)\n",
    "\n",
    "# Label encoding string fields\n",
    "encoder = LabelEncoder()\n",
    "subset_file['activity_name'] = encoder.fit_transform(subset_file['activity_name'])\n",
    "subset_file['user_id'] = encoder.fit_transform(subset_file['user_id'])\n",
    "\n",
    "# Selecting features for clustering\n",
    "X = subset_file[['hour', 'minute']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "subset_file['cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "subset_file.head()\n",
    "\n",
    "# plt.scatter(subset_file['hour'], subset_file['activity_name'], c=subset_file['cluster'])\n",
    "# plt.xlabel('Hour of the Day')\n",
    "# plt.ylabel('Activity')\n",
    "# plt.title('K-means Clustering of ADL Data')\n",
    "# plt.show()\n",
    "\n",
    "time_slots = [7, 8, 10, 12, 14, 16, 18, 20, 21, 22]\n",
    "\n",
    "# Initialize an empty dictionary to store the recommended meal times for each cluster and time slot\n",
    "meal_times_recommendations = {}\n",
    "\n",
    "# Group the data by cluster and time slot and calculate the mean hour for each group\n",
    "for cluster_id in range(3):\n",
    "    cluster_data = subset_file[subset_file['cluster'] == cluster_id]\n",
    "    cluster_recommendations = []\n",
    "    \n",
    "    for i in range(len(time_slots) - 1):\n",
    "        start_time = time_slots[i]\n",
    "        end_time = time_slots[i + 1]\n",
    "        \n",
    "        # Get the mean hour for the current time slot in the cluster\n",
    "        mean_hour = cluster_data[(cluster_data['hour'] >= start_time) & (cluster_data['hour'] < end_time)]['hour'].mean()\n",
    "        cluster_recommendations.append(round(mean_hour))\n",
    "    \n",
    "    meal_times_recommendations[f'Cluster {cluster_id + 1}'] = cluster_recommendations\n",
    "\n",
    "# Convert the dictionary to a DataFrame for easier visualization\n",
    "recommendations_df = pd.DataFrame(meal_times_recommendations)\n",
    "recommendations_df.index = ['Morning', 'Morning activities 1', 'Morning snack', 'Morning activities 2', 'Lunch', 'Afternoon activities', 'Afternoon Snack', 'Evening activities', 'Dinner']\n",
    "\n",
    "user_timetable = {\n",
    "    'Morning': [7],\n",
    "    'Morning activities 1': [8],\n",
    "    'Morning snack': [10], \n",
    "    'Morning activities 2': [11],\n",
    "    'Lunch': [13], \n",
    "    'Afternoon activities': [14], \n",
    "    'Afternoon Snack': [16],\n",
    "    'Evening activities': [17], \n",
    "    'Dinner': [19]\n",
    "}\n",
    "\n",
    "for index, row in recommendations_df.iterrows():\n",
    "    cluster_1 = row['Cluster 1']\n",
    "    cluster_2 = row['Cluster 2']\n",
    "    cluster_3 = row['Cluster 3']\n",
    "    mean_time = round((cluster_1 + cluster_2 + cluster_3)/3)\n",
    "    user_timetable[row.name] = mean_time\n",
    "\n",
    "print(user_timetable)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
